{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "text-summarization-with-transformers.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaival99/News-Summarization-using-Abstractive-Techniques/blob/main/Transformers/text_summarization_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgements\n",
        "\n",
        "The code for the transformer model is take from  this tutorial https://www.tensorflow.org/text/tutorials/transformer"
      ],
      "metadata": {
        "id": "MFGP5ltL0S2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDBrP3rZ0YXi",
        "outputId": "f5393c84-e247-4f5e-e776-3723fa64268c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages needed and Importing Libraries"
      ],
      "metadata": {
        "id": "nM115Ldw0S2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl  --quiet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:35.025365Z",
          "iopub.execute_input": "2022-04-18T15:24:35.025718Z",
          "iopub.status.idle": "2022-04-18T15:24:40.543738Z",
          "shell.execute_reply.started": "2022-04-18T15:24:35.025687Z",
          "shell.execute_reply": "2022-04-18T15:24:40.542722Z"
        },
        "trusted": true,
        "id": "RMo4Kpaf0S2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:43.428633Z",
          "iopub.execute_input": "2022-04-18T15:24:43.428953Z",
          "iopub.status.idle": "2022-04-18T15:24:43.435182Z",
          "shell.execute_reply.started": "2022-04-18T15:24:43.428917Z",
          "shell.execute_reply": "2022-04-18T15:24:43.434218Z"
        },
        "trusted": true,
        "id": "khoAv2ei0S2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_LEN = 1000\n",
        "DECODER_LEN = 90\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 50000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T15:24:46.581667Z",
          "iopub.execute_input": "2022-04-18T15:24:46.581992Z",
          "iopub.status.idle": "2022-04-18T15:24:46.585937Z",
          "shell.execute_reply.started": "2022-04-18T15:24:46.58196Z",
          "shell.execute_reply": "2022-04-18T15:24:46.585117Z"
        },
        "trusted": true,
        "id": "gjvolKFq0S2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "After creating the dataframe we apply Start of Sentence(<SOS>) and End of Sentence(<EOS>) tokens. \n",
        "These sentences are then tokenized and padded to fix length."
      ],
      "metadata": {
        "id": "r99C75Wz0S2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news = pd.read_csv(\"/content/drive/MyDrive/DL Project/train.csv\")\n",
        "news = news.sample(frac=0.2)\n",
        "news.drop(['id'], axis=1, inplace=True)\n",
        "news.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:00:58.517146Z",
          "iopub.execute_input": "2022-04-18T16:00:58.517509Z",
          "iopub.status.idle": "2022-04-18T16:01:09.446906Z",
          "shell.execute_reply.started": "2022-04-18T16:00:58.517476Z",
          "shell.execute_reply": "2022-04-18T16:01:09.44608Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0lJdW1d-0S2d",
        "outputId": "6dc54efe-a433-45af-e585-13e4a099bb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  article  \\\n",
              "278333  (CNN) -- With Republicans back in control of t...   \n",
              "144485  Distraught: Liz Lowther, pictured, said she wa...   \n",
              "163916  By . Pa Reporter . Ahead of the opening weeken...   \n",
              "189198  'I would not be recovering as fast as . I am i...   \n",
              "126959  Liverpool owner John Henry has responded to fa...   \n",
              "\n",
              "                                               highlights  \n",
              "278333  House Republican Leader John Boehner is expect...  \n",
              "144485  Liz Lowther wrote to Virgin Media notifying co...  \n",
              "163916  Dejan Lovren and Rickie Lambert could line up ...  \n",
              "189198  Ana Kessel, 20, was riding her scooter when Mi...  \n",
              "126959  Liverpool fans held banners protesting the ris...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-258171e2-4e19-4e50-9b57-3afff92c68d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>278333</th>\n",
              "      <td>(CNN) -- With Republicans back in control of t...</td>\n",
              "      <td>House Republican Leader John Boehner is expect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144485</th>\n",
              "      <td>Distraught: Liz Lowther, pictured, said she wa...</td>\n",
              "      <td>Liz Lowther wrote to Virgin Media notifying co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163916</th>\n",
              "      <td>By . Pa Reporter . Ahead of the opening weeken...</td>\n",
              "      <td>Dejan Lovren and Rickie Lambert could line up ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189198</th>\n",
              "      <td>'I would not be recovering as fast as . I am i...</td>\n",
              "      <td>Ana Kessel, 20, was riding her scooter when Mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126959</th>\n",
              "      <td>Liverpool owner John Henry has responded to fa...</td>\n",
              "      <td>Liverpool fans held banners protesting the ris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-258171e2-4e19-4e50-9b57-3afff92c68d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-258171e2-4e19-4e50-9b57-3afff92c68d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-258171e2-4e19-4e50-9b57-3afff92c68d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:20.346006Z",
          "iopub.execute_input": "2022-04-18T16:14:20.346351Z",
          "iopub.status.idle": "2022-04-18T16:14:20.351941Z",
          "shell.execute_reply.started": "2022-04-18T16:14:20.346317Z",
          "shell.execute_reply": "2022-04-18T16:14:20.351017Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jY65JSb0S2e",
        "outputId": "10e3ff31-533b-447e-fb17-a32f1b979a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57423, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article = news['article']\n",
        "summary = news['highlights']\n",
        "article = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
        "summary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:19.688995Z",
          "iopub.execute_input": "2022-04-18T16:01:19.68933Z",
          "iopub.status.idle": "2022-04-18T16:01:20.025837Z",
          "shell.execute_reply.started": "2022-04-18T16:01:19.689298Z",
          "shell.execute_reply": "2022-04-18T16:01:20.024986Z"
        },
        "trusted": true,
        "id": "Y7envpF50S2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n",
        "    return text\n",
        "article = article.apply(lambda x: preprocess(x))\n",
        "summary = summary.apply(lambda x: preprocess(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:22.165668Z",
          "iopub.execute_input": "2022-04-18T16:01:22.165974Z",
          "iopub.status.idle": "2022-04-18T16:01:22.635631Z",
          "shell.execute_reply.started": "2022-04-18T16:01:22.165944Z",
          "shell.execute_reply": "2022-04-18T16:01:22.634792Z"
        },
        "trusted": true,
        "id": "z6mVkTlP0S2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "article_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
        "article_tokenizer.fit_on_texts(article)\n",
        "summary_tokenizer.fit_on_texts(summary)\n",
        "inputs = article_tokenizer.texts_to_sequences(article)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:01:25.411382Z",
          "iopub.execute_input": "2022-04-18T16:01:25.4117Z",
          "iopub.status.idle": "2022-04-18T16:03:26.338306Z",
          "shell.execute_reply.started": "2022-04-18T16:01:25.41167Z",
          "shell.execute_reply": "2022-04-18T16:03:26.337416Z"
        },
        "trusted": true,
        "id": "zioOqkmZ0S2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\n",
        "DECODER_VOCAB = len(summary_tokenizer.word_index) + 1\n",
        "print(ENCODER_VOCAB, DECODER_VOCAB)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:03:58.585997Z",
          "iopub.execute_input": "2022-04-18T16:03:58.586347Z",
          "iopub.status.idle": "2022-04-18T16:03:58.591777Z",
          "shell.execute_reply.started": "2022-04-18T16:03:58.586314Z",
          "shell.execute_reply": "2022-04-18T16:03:58.590723Z"
        },
        "trusted": true,
        "id": "4ODXThm10S2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5598f61-e23e-4ae1-eb65-82e631d3a111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "332385 101037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
        "inputs = tf.cast(inputs, dtype=tf.int64)\n",
        "targets = tf.cast(targets, dtype=tf.int64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:04:30.482628Z",
          "iopub.execute_input": "2022-04-18T16:04:30.482933Z",
          "iopub.status.idle": "2022-04-18T16:04:45.845899Z",
          "shell.execute_reply.started": "2022-04-18T16:04:30.482903Z",
          "shell.execute_reply": "2022-04-18T16:04:45.844919Z"
        },
        "trusted": true,
        "id": "LUsjTvKK0S2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:04:56.339727Z",
          "iopub.execute_input": "2022-04-18T16:04:56.340029Z",
          "iopub.status.idle": "2022-04-18T16:04:56.892821Z",
          "shell.execute_reply.started": "2022-04-18T16:04:56.34Z",
          "shell.execute_reply": "2022-04-18T16:04:56.891974Z"
        },
        "trusted": true,
        "id": "d0rCLqpq0S2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Model\n",
        "\n",
        "The next several blocks of code contain the vanilla Transformer model.\n",
        "\n",
        "If you want to know about what they are and how they work I suggest this video: https://www.youtube.com/watch?v=4Bdc55j80l8\n",
        "\n",
        "It does an excellent job of giving an overview about them and helped me in understanding them."
      ],
      "metadata": {
        "id": "IuIqp8Li0S2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:29.054073Z",
          "iopub.execute_input": "2022-04-18T16:14:29.054409Z",
          "iopub.status.idle": "2022-04-18T16:14:29.066612Z",
          "shell.execute_reply.started": "2022-04-18T16:14:29.054377Z",
          "shell.execute_reply": "2022-04-18T16:14:29.065698Z"
        },
        "trusted": true,
        "id": "y3vDlqeM0S2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:30.05906Z",
          "iopub.execute_input": "2022-04-18T16:14:30.05941Z",
          "iopub.status.idle": "2022-04-18T16:14:30.07051Z",
          "shell.execute_reply.started": "2022-04-18T16:14:30.059375Z",
          "shell.execute_reply": "2022-04-18T16:14:30.06963Z"
        },
        "trusted": true,
        "id": "3FXaCuOD0S2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:30.692961Z",
          "iopub.execute_input": "2022-04-18T16:14:30.69329Z",
          "iopub.status.idle": "2022-04-18T16:14:30.701169Z",
          "shell.execute_reply.started": "2022-04-18T16:14:30.693259Z",
          "shell.execute_reply": "2022-04-18T16:14:30.700272Z"
        },
        "trusted": true,
        "id": "GLG5uINW0S2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:31.349405Z",
          "iopub.execute_input": "2022-04-18T16:14:31.349715Z",
          "iopub.status.idle": "2022-04-18T16:14:31.359319Z",
          "shell.execute_reply.started": "2022-04-18T16:14:31.349686Z",
          "shell.execute_reply": "2022-04-18T16:14:31.358258Z"
        },
        "trusted": true,
        "id": "Mk4fBOLR0S2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x\n",
        "    \n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "        \n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:31.975409Z",
          "iopub.execute_input": "2022-04-18T16:14:31.975731Z",
          "iopub.status.idle": "2022-04-18T16:14:31.990616Z",
          "shell.execute_reply.started": "2022-04-18T16:14:31.975698Z",
          "shell.execute_reply": "2022-04-18T16:14:31.989283Z"
        },
        "trusted": true,
        "id": "OonzhDmr0S2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T16:14:32.562814Z",
          "iopub.execute_input": "2022-04-18T16:14:32.563136Z",
          "iopub.status.idle": "2022-04-18T16:14:32.570437Z",
          "shell.execute_reply.started": "2022-04-18T16:14:32.563104Z",
          "shell.execute_reply": "2022-04-18T16:14:32.569422Z"
        },
        "trusted": true,
        "id": "V-iZbFMy0S2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 3\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 4\n",
        "dropout_rate = 0.2\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:22.511999Z",
          "iopub.execute_input": "2022-04-18T21:13:22.51236Z",
          "iopub.status.idle": "2022-04-18T21:13:22.51764Z",
          "shell.execute_reply.started": "2022-04-18T21:13:22.512327Z",
          "shell.execute_reply": "2022-04-18T21:13:22.515666Z"
        },
        "trusted": true,
        "id": "tzLrp9fT0S2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Learning Rate"
      ],
      "metadata": {
        "id": "47TqR1e10S2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:35.294707Z",
          "iopub.execute_input": "2022-04-18T21:13:35.295016Z",
          "iopub.status.idle": "2022-04-18T21:13:35.301191Z",
          "shell.execute_reply.started": "2022-04-18T21:13:35.294986Z",
          "shell.execute_reply": "2022-04-18T21:13:35.300053Z"
        },
        "trusted": true,
        "id": "p0fEDMRn0S2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:35.955005Z",
          "iopub.execute_input": "2022-04-18T21:13:35.955378Z",
          "iopub.status.idle": "2022-04-18T21:13:35.960798Z",
          "shell.execute_reply.started": "2022-04-18T21:13:35.955346Z",
          "shell.execute_reply": "2022-04-18T21:13:35.95995Z"
        },
        "trusted": true,
        "id": "XUicG44r0S2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:36.730048Z",
          "iopub.execute_input": "2022-04-18T21:13:36.730401Z",
          "iopub.status.idle": "2022-04-18T21:13:36.903049Z",
          "shell.execute_reply.started": "2022-04-18T21:13:36.73037Z",
          "shell.execute_reply": "2022-04-18T21:13:36.901924Z"
        },
        "trusted": true,
        "id": "jrjb6Tza0S2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d7e95a71-8269-43eb-d13e-0e2bdc143e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Loss and Accuracy"
      ],
      "metadata": {
        "id": "K2YNbGbA0S2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:38.099689Z",
          "iopub.execute_input": "2022-04-18T21:13:38.100014Z",
          "iopub.status.idle": "2022-04-18T21:13:38.108656Z",
          "shell.execute_reply.started": "2022-04-18T21:13:38.099981Z",
          "shell.execute_reply": "2022-04-18T21:13:38.107394Z"
        },
        "trusted": true,
        "id": "8DYtfybT0S2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:43.657543Z",
          "iopub.execute_input": "2022-04-18T21:13:43.657853Z",
          "iopub.status.idle": "2022-04-18T21:13:43.675333Z",
          "shell.execute_reply.started": "2022-04-18T21:13:43.657824Z",
          "shell.execute_reply": "2022-04-18T21:13:43.674614Z"
        },
        "trusted": true,
        "id": "dX5Zwhu30S2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=ENCODER_VOCAB,\n",
        "    target_vocab_size=DECODER_VOCAB,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:44.626431Z",
          "iopub.execute_input": "2022-04-18T21:13:44.62684Z",
          "iopub.status.idle": "2022-04-18T21:13:45.366521Z",
          "shell.execute_reply.started": "2022-04-18T21:13:44.6268Z",
          "shell.execute_reply": "2022-04-18T21:13:45.365483Z"
        },
        "trusted": true,
        "id": "hYkEXLlg0S2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:45.792139Z",
          "iopub.execute_input": "2022-04-18T21:13:45.79255Z",
          "iopub.status.idle": "2022-04-18T21:13:45.798183Z",
          "shell.execute_reply.started": "2022-04-18T21:13:45.792511Z",
          "shell.execute_reply": "2022-04-18T21:13:45.797153Z"
        },
        "trusted": true,
        "id": "rkwJ3g2E0S2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/DL Project\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:46.898611Z",
          "iopub.execute_input": "2022-04-18T21:13:46.89893Z",
          "iopub.status.idle": "2022-04-18T21:13:46.922022Z",
          "shell.execute_reply.started": "2022-04-18T21:13:46.898899Z",
          "shell.execute_reply": "2022-04-18T21:13:46.921249Z"
        },
        "trusted": true,
        "id": "lSQnsRdY0S2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997b42d2-c757-4065-c060-edc9753ea46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:47.919065Z",
          "iopub.execute_input": "2022-04-18T21:13:47.919419Z",
          "iopub.status.idle": "2022-04-18T21:13:48.171061Z",
          "shell.execute_reply.started": "2022-04-18T21:13:47.919387Z",
          "shell.execute_reply": "2022-04-18T21:13:48.170084Z"
        },
        "trusted": true,
        "id": "D_diTdOx0S2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class model_per_epoch(keras.callbacks.Callback):\n",
        "#     def __init__(self, model,filepath,save_best_only):\n",
        "#         self.filepath=filepath\n",
        "#         self.model=model\n",
        "#         self.save_best_only=save_best_only\n",
        "#         self.lowest_loss=np.inf\n",
        "#         self.best_weights=self.model.get_weights()\n",
        "#     def on_epoch_end(self,epoch, logs=None):\n",
        "#         v_loss=logs.get('val_loss')\n",
        "#         if v_loss< self.lowest_loss:\n",
        "#             self.lowest_loss =v_loss\n",
        "#             self.best_weights=self.model.get_weights()\n",
        "#             self.best_epoch=epoch +1\n",
        "#         if self.save_best_only==False:\n",
        "#             name= str(epoch) +'-' + str(v_loss)[:str(v_loss).rfind('.')+3] + '.h5'\n",
        "#             file_id=os.path.join(self.filepath, name)\n",
        "#             self.model.save(file_id)\n",
        "#     def on_train_end(self, logs=None):\n",
        "#         if self.save_best_only == True:\n",
        "#             self.model.set_weights(self.best_weights)\n",
        "#             name= str(self.best_epoch) +'-' + str(self.lowest_loss)[:str(self.lowest_loss).rfind('.')+3] + '.h5'\n",
        "#             file_id=os.path.join(self.filepath, name)\n",
        "#             self.model.save(file_id)\n",
        "#             print(' model is returned with best weiights from epoch ', self.best_epoch)\n",
        "            \n",
        "# save_dir=r'c:\\Temp\\models'\n",
        "# save_best_only= True\n",
        "# callbacks=[model_per_epoch(model, save_dir, save_best_only)]  "
      ],
      "metadata": {
        "id": "rd-TjRdH1dTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "u8C5EKDv0S2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        if batch % 100 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "   \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:13:51.107977Z",
          "iopub.execute_input": "2022-04-18T21:13:51.10835Z"
        },
        "trusted": true,
        "id": "PGEgyJ6H0S2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66299831-0a0f-4bcc-a482-dd53880ce675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 5.7366 Accuracy 0.2023\n",
            "Epoch 1 Batch 100 Loss 5.5232 Accuracy 0.2023\n",
            "Epoch 1 Batch 200 Loss 5.5330 Accuracy 0.2023\n",
            "Epoch 1 Batch 300 Loss 5.5433 Accuracy 0.2024\n",
            "Epoch 1 Batch 400 Loss 5.5574 Accuracy 0.2024\n",
            "Epoch 1 Batch 500 Loss 5.5521 Accuracy 0.2025\n",
            "Epoch 1 Batch 600 Loss 5.5506 Accuracy 0.2025\n",
            "Epoch 1 Batch 700 Loss 5.5507 Accuracy 0.2025\n",
            "Epoch 1 Batch 800 Loss 5.5570 Accuracy 0.2026\n",
            "Epoch 1 Batch 900 Loss 5.5598 Accuracy 0.2026\n",
            "Epoch 1 Batch 1000 Loss 5.5655 Accuracy 0.2027\n",
            "Epoch 1 Batch 1100 Loss 5.5696 Accuracy 0.2027\n",
            "Epoch 1 Batch 1200 Loss 5.5774 Accuracy 0.2027\n",
            "Epoch 1 Batch 1300 Loss 5.5800 Accuracy 0.2028\n",
            "Epoch 1 Batch 1400 Loss 5.5871 Accuracy 0.2028\n",
            "Epoch 1 Batch 1500 Loss 5.5927 Accuracy 0.2028\n",
            "Epoch 1 Batch 1600 Loss 5.5972 Accuracy 0.2029\n",
            "Epoch 1 Batch 1700 Loss 5.6019 Accuracy 0.2029\n",
            "Epoch 1 Batch 1800 Loss 5.6076 Accuracy 0.2029\n",
            "Epoch 1 Batch 1900 Loss 5.6108 Accuracy 0.2030\n",
            "Epoch 1 Batch 2000 Loss 5.6140 Accuracy 0.2030\n",
            "Epoch 1 Batch 2100 Loss 5.6201 Accuracy 0.2030\n",
            "Epoch 1 Batch 2200 Loss 5.6241 Accuracy 0.2031\n",
            "Epoch 1 Batch 2300 Loss 5.6253 Accuracy 0.2031\n",
            "Epoch 1 Batch 2400 Loss 5.6274 Accuracy 0.2031\n",
            "Epoch 1 Batch 2500 Loss 5.6304 Accuracy 0.2032\n",
            "Epoch 1 Batch 2600 Loss 5.6319 Accuracy 0.2032\n",
            "Epoch 1 Batch 2700 Loss 5.6353 Accuracy 0.2033\n",
            "Epoch 1 Batch 2800 Loss 5.6363 Accuracy 0.2033\n",
            "Epoch 1 Batch 2900 Loss 5.6372 Accuracy 0.2033\n",
            "Epoch 1 Batch 3000 Loss 5.6392 Accuracy 0.2034\n",
            "Epoch 1 Batch 3100 Loss 5.6405 Accuracy 0.2034\n",
            "Epoch 1 Batch 3200 Loss 5.6426 Accuracy 0.2034\n",
            "Epoch 1 Batch 3300 Loss 5.6435 Accuracy 0.2035\n",
            "Epoch 1 Batch 3400 Loss 5.6463 Accuracy 0.2035\n",
            "Epoch 1 Batch 3500 Loss 5.6489 Accuracy 0.2035\n",
            "Epoch 1 Loss 5.6513 Accuracy 0.2035\n",
            "Time taken for 1 epoch: 1287.296980381012 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 6.0927 Accuracy 0.2035\n",
            "Epoch 2 Batch 100 Loss 5.4846 Accuracy 0.2036\n",
            "Epoch 2 Batch 200 Loss 5.5027 Accuracy 0.2036\n",
            "Epoch 2 Batch 300 Loss 5.5017 Accuracy 0.2037\n",
            "Epoch 2 Batch 400 Loss 5.5191 Accuracy 0.2037\n",
            "Epoch 2 Batch 500 Loss 5.5246 Accuracy 0.2037\n",
            "Epoch 2 Batch 600 Loss 5.5326 Accuracy 0.2038\n",
            "Epoch 2 Batch 700 Loss 5.5425 Accuracy 0.2038\n",
            "Epoch 2 Batch 800 Loss 5.5494 Accuracy 0.2039\n",
            "Epoch 2 Batch 900 Loss 5.5581 Accuracy 0.2039\n",
            "Epoch 2 Batch 1000 Loss 5.5646 Accuracy 0.2039\n",
            "Epoch 2 Batch 1100 Loss 5.5718 Accuracy 0.2040\n",
            "Epoch 2 Batch 1200 Loss 5.5759 Accuracy 0.2040\n",
            "Epoch 2 Batch 1300 Loss 5.5797 Accuracy 0.2040\n",
            "Epoch 2 Batch 1400 Loss 5.5814 Accuracy 0.2041\n",
            "Epoch 2 Batch 1500 Loss 5.5854 Accuracy 0.2041\n",
            "Epoch 2 Batch 1600 Loss 5.5891 Accuracy 0.2041\n",
            "Epoch 2 Batch 1700 Loss 5.5928 Accuracy 0.2042\n",
            "Epoch 2 Batch 1800 Loss 5.5986 Accuracy 0.2042\n",
            "Epoch 2 Batch 1900 Loss 5.6022 Accuracy 0.2043\n",
            "Epoch 2 Batch 2000 Loss 5.6071 Accuracy 0.2043\n",
            "Epoch 2 Batch 2100 Loss 5.6082 Accuracy 0.2043\n",
            "Epoch 2 Batch 2200 Loss 5.6110 Accuracy 0.2044\n",
            "Epoch 2 Batch 2300 Loss 5.6141 Accuracy 0.2044\n",
            "Epoch 2 Batch 2400 Loss 5.6158 Accuracy 0.2044\n",
            "Epoch 2 Batch 2500 Loss 5.6171 Accuracy 0.2044\n",
            "Epoch 2 Batch 2600 Loss 5.6190 Accuracy 0.2045\n",
            "Epoch 2 Batch 2700 Loss 5.6211 Accuracy 0.2045\n",
            "Epoch 2 Batch 2800 Loss 5.6234 Accuracy 0.2045\n",
            "Epoch 2 Batch 2900 Loss 5.6256 Accuracy 0.2046\n",
            "Epoch 2 Batch 3000 Loss 5.6282 Accuracy 0.2046\n",
            "Epoch 2 Batch 3100 Loss 5.6306 Accuracy 0.2046\n",
            "Epoch 2 Batch 3200 Loss 5.6330 Accuracy 0.2047\n",
            "Epoch 2 Batch 3300 Loss 5.6344 Accuracy 0.2047\n",
            "Epoch 2 Batch 3400 Loss 5.6357 Accuracy 0.2047\n",
            "Epoch 2 Batch 3500 Loss 5.6384 Accuracy 0.2048\n",
            "Epoch 2 Loss 5.6402 Accuracy 0.2048\n",
            "Time taken for 1 epoch: 1286.397578239441 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 5.3550 Accuracy 0.2048\n",
            "Epoch 3 Batch 100 Loss 5.5022 Accuracy 0.2048\n",
            "Epoch 3 Batch 200 Loss 5.5326 Accuracy 0.2049\n",
            "Epoch 3 Batch 300 Loss 5.5295 Accuracy 0.2049\n",
            "Epoch 3 Batch 400 Loss 5.5295 Accuracy 0.2049\n",
            "Epoch 3 Batch 500 Loss 5.5285 Accuracy 0.2050\n",
            "Epoch 3 Batch 600 Loss 5.5331 Accuracy 0.2050\n",
            "Epoch 3 Batch 700 Loss 5.5355 Accuracy 0.2051\n",
            "Epoch 3 Batch 800 Loss 5.5419 Accuracy 0.2051\n",
            "Epoch 3 Batch 900 Loss 5.5441 Accuracy 0.2051\n",
            "Epoch 3 Batch 1000 Loss 5.5479 Accuracy 0.2052\n",
            "Epoch 3 Batch 1100 Loss 5.5548 Accuracy 0.2052\n",
            "Epoch 3 Batch 1200 Loss 5.5608 Accuracy 0.2052\n",
            "Epoch 3 Batch 1300 Loss 5.5677 Accuracy 0.2053\n",
            "Epoch 3 Batch 1400 Loss 5.5742 Accuracy 0.2053\n",
            "Epoch 3 Batch 1500 Loss 5.5773 Accuracy 0.2053\n",
            "Epoch 3 Batch 1600 Loss 5.5822 Accuracy 0.2054\n",
            "Epoch 3 Batch 1700 Loss 5.5862 Accuracy 0.2054\n",
            "Epoch 3 Batch 1800 Loss 5.5888 Accuracy 0.2054\n",
            "Epoch 3 Batch 1900 Loss 5.5919 Accuracy 0.2055\n",
            "Epoch 3 Batch 2000 Loss 5.5941 Accuracy 0.2055\n",
            "Epoch 3 Batch 2100 Loss 5.5974 Accuracy 0.2055\n",
            "Epoch 3 Batch 2200 Loss 5.5996 Accuracy 0.2056\n",
            "Epoch 3 Batch 2300 Loss 5.6017 Accuracy 0.2056\n",
            "Epoch 3 Batch 2400 Loss 5.6047 Accuracy 0.2056\n",
            "Epoch 3 Batch 2500 Loss 5.6063 Accuracy 0.2057\n",
            "Epoch 3 Batch 2600 Loss 5.6088 Accuracy 0.2057\n",
            "Epoch 3 Batch 2700 Loss 5.6121 Accuracy 0.2057\n",
            "Epoch 3 Batch 2800 Loss 5.6144 Accuracy 0.2058\n",
            "Epoch 3 Batch 2900 Loss 5.6165 Accuracy 0.2058\n",
            "Epoch 3 Batch 3000 Loss 5.6179 Accuracy 0.2058\n",
            "Epoch 3 Batch 3100 Loss 5.6212 Accuracy 0.2059\n",
            "Epoch 3 Batch 3200 Loss 5.6237 Accuracy 0.2059\n",
            "Epoch 3 Batch 3300 Loss 5.6257 Accuracy 0.2059\n",
            "Epoch 3 Batch 3400 Loss 5.6286 Accuracy 0.2060\n",
            "Epoch 3 Batch 3500 Loss 5.6301 Accuracy 0.2060\n",
            "Epoch 3 Loss 5.6308 Accuracy 0.2060\n",
            "Time taken for 1 epoch: 1286.412521123886 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.5616 Accuracy 0.2060\n",
            "Epoch 4 Batch 100 Loss 5.4846 Accuracy 0.2061\n",
            "Epoch 4 Batch 200 Loss 5.5084 Accuracy 0.2061\n",
            "Epoch 4 Batch 300 Loss 5.5095 Accuracy 0.2061\n",
            "Epoch 4 Batch 400 Loss 5.5104 Accuracy 0.2062\n",
            "Epoch 4 Batch 500 Loss 5.5017 Accuracy 0.2062\n",
            "Epoch 4 Batch 600 Loss 5.5073 Accuracy 0.2062\n",
            "Epoch 4 Batch 700 Loss 5.5155 Accuracy 0.2063\n",
            "Epoch 4 Batch 800 Loss 5.5230 Accuracy 0.2063\n",
            "Epoch 4 Batch 900 Loss 5.5320 Accuracy 0.2064\n",
            "Epoch 4 Batch 1000 Loss 5.5361 Accuracy 0.2064\n",
            "Epoch 4 Batch 1100 Loss 5.5402 Accuracy 0.2064\n",
            "Epoch 4 Batch 1200 Loss 5.5474 Accuracy 0.2065\n",
            "Epoch 4 Batch 1300 Loss 5.5569 Accuracy 0.2065\n",
            "Epoch 4 Batch 1400 Loss 5.5619 Accuracy 0.2065\n",
            "Epoch 4 Batch 1500 Loss 5.5648 Accuracy 0.2066\n",
            "Epoch 4 Batch 1600 Loss 5.5693 Accuracy 0.2066\n",
            "Epoch 4 Batch 1700 Loss 5.5707 Accuracy 0.2066\n",
            "Epoch 4 Batch 1800 Loss 5.5740 Accuracy 0.2067\n",
            "Epoch 4 Batch 1900 Loss 5.5777 Accuracy 0.2067\n",
            "Epoch 4 Batch 2000 Loss 5.5797 Accuracy 0.2067\n",
            "Epoch 4 Batch 2100 Loss 5.5837 Accuracy 0.2067\n",
            "Epoch 4 Batch 2200 Loss 5.5871 Accuracy 0.2068\n",
            "Epoch 4 Batch 2300 Loss 5.5895 Accuracy 0.2068\n",
            "Epoch 4 Batch 2400 Loss 5.5926 Accuracy 0.2068\n",
            "Epoch 4 Batch 2500 Loss 5.5945 Accuracy 0.2069\n",
            "Epoch 4 Batch 2600 Loss 5.5953 Accuracy 0.2069\n",
            "Epoch 4 Batch 2700 Loss 5.5973 Accuracy 0.2069\n",
            "Epoch 4 Batch 2800 Loss 5.6000 Accuracy 0.2070\n",
            "Epoch 4 Batch 2900 Loss 5.6029 Accuracy 0.2070\n",
            "Epoch 4 Batch 3000 Loss 5.6055 Accuracy 0.2070\n",
            "Epoch 4 Batch 3100 Loss 5.6073 Accuracy 0.2071\n",
            "Epoch 4 Batch 3200 Loss 5.6091 Accuracy 0.2071\n",
            "Epoch 4 Batch 3300 Loss 5.6113 Accuracy 0.2071\n",
            "Epoch 4 Batch 3400 Loss 5.6152 Accuracy 0.2071\n",
            "Epoch 4 Batch 3500 Loss 5.6168 Accuracy 0.2072\n",
            "Epoch 4 Loss 5.6194 Accuracy 0.2072\n",
            "Time taken for 1 epoch: 1287.2874727249146 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 5.5800 Accuracy 0.2072\n",
            "Epoch 5 Batch 100 Loss 5.4668 Accuracy 0.2072\n",
            "Epoch 5 Batch 200 Loss 5.4727 Accuracy 0.2073\n",
            "Epoch 5 Batch 300 Loss 5.4894 Accuracy 0.2073\n",
            "Epoch 5 Batch 400 Loss 5.4963 Accuracy 0.2073\n",
            "Epoch 5 Batch 500 Loss 5.5097 Accuracy 0.2074\n",
            "Epoch 5 Batch 600 Loss 5.5173 Accuracy 0.2074\n",
            "Epoch 5 Batch 700 Loss 5.5235 Accuracy 0.2074\n",
            "Epoch 5 Batch 800 Loss 5.5284 Accuracy 0.2075\n",
            "Epoch 5 Batch 900 Loss 5.5354 Accuracy 0.2075\n",
            "Epoch 5 Batch 1000 Loss 5.5418 Accuracy 0.2075\n",
            "Epoch 5 Batch 1100 Loss 5.5449 Accuracy 0.2076\n",
            "Epoch 5 Batch 1200 Loss 5.5494 Accuracy 0.2076\n",
            "Epoch 5 Batch 1300 Loss 5.5537 Accuracy 0.2076\n",
            "Epoch 5 Batch 1400 Loss 5.5557 Accuracy 0.2077\n",
            "Epoch 5 Batch 1500 Loss 5.5585 Accuracy 0.2077\n",
            "Epoch 5 Batch 1600 Loss 5.5590 Accuracy 0.2077\n",
            "Epoch 5 Batch 1700 Loss 5.5608 Accuracy 0.2078\n",
            "Epoch 5 Batch 1800 Loss 5.5631 Accuracy 0.2078\n",
            "Epoch 5 Batch 1900 Loss 5.5672 Accuracy 0.2078\n",
            "Epoch 5 Batch 2000 Loss 5.5736 Accuracy 0.2079\n",
            "Epoch 5 Batch 2100 Loss 5.5770 Accuracy 0.2079\n",
            "Epoch 5 Batch 2200 Loss 5.5816 Accuracy 0.2079\n",
            "Epoch 5 Batch 2300 Loss 5.5840 Accuracy 0.2080\n",
            "Epoch 5 Batch 2400 Loss 5.5872 Accuracy 0.2080\n",
            "Epoch 5 Batch 2500 Loss 5.5896 Accuracy 0.2080\n",
            "Epoch 5 Batch 2600 Loss 5.5930 Accuracy 0.2081\n",
            "Epoch 5 Batch 2700 Loss 5.5947 Accuracy 0.2081\n",
            "Epoch 5 Batch 2800 Loss 5.5968 Accuracy 0.2081\n",
            "Epoch 5 Batch 2900 Loss 5.5982 Accuracy 0.2082\n",
            "Epoch 5 Batch 3000 Loss 5.5994 Accuracy 0.2082\n",
            "Epoch 5 Batch 3100 Loss 5.6028 Accuracy 0.2082\n",
            "Epoch 5 Batch 3200 Loss 5.6043 Accuracy 0.2082\n",
            "Epoch 5 Batch 3300 Loss 5.6061 Accuracy 0.2083\n",
            "Epoch 5 Batch 3400 Loss 5.6083 Accuracy 0.2083\n",
            "Epoch 5 Batch 3500 Loss 5.6107 Accuracy 0.2083\n",
            "Saving checkpoint for epoch 5 at /content/drive/MyDrive/DL Project/ckpt-7\n",
            "Epoch 5 Loss 5.6113 Accuracy 0.2084\n",
            "Time taken for 1 epoch: 1292.1316857337952 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 5.5456 Accuracy 0.2084\n",
            "Epoch 6 Batch 100 Loss 5.4683 Accuracy 0.2084\n",
            "Epoch 6 Batch 200 Loss 5.4752 Accuracy 0.2084\n",
            "Epoch 6 Batch 300 Loss 5.4764 Accuracy 0.2085\n",
            "Epoch 6 Batch 400 Loss 5.4806 Accuracy 0.2085\n",
            "Epoch 6 Batch 500 Loss 5.4976 Accuracy 0.2085\n",
            "Epoch 6 Batch 600 Loss 5.5044 Accuracy 0.2086\n",
            "Epoch 6 Batch 700 Loss 5.5074 Accuracy 0.2086\n",
            "Epoch 6 Batch 800 Loss 5.5112 Accuracy 0.2086\n",
            "Epoch 6 Batch 900 Loss 5.5154 Accuracy 0.2087\n",
            "Epoch 6 Batch 1000 Loss 5.5226 Accuracy 0.2087\n",
            "Epoch 6 Batch 1100 Loss 5.5266 Accuracy 0.2087\n",
            "Epoch 6 Batch 1200 Loss 5.5337 Accuracy 0.2088\n",
            "Epoch 6 Batch 1300 Loss 5.5399 Accuracy 0.2088\n",
            "Epoch 6 Batch 1400 Loss 5.5417 Accuracy 0.2088\n",
            "Epoch 6 Batch 1500 Loss 5.5469 Accuracy 0.2089\n",
            "Epoch 6 Batch 1600 Loss 5.5487 Accuracy 0.2089\n",
            "Epoch 6 Batch 1700 Loss 5.5523 Accuracy 0.2089\n",
            "Epoch 6 Batch 1800 Loss 5.5557 Accuracy 0.2089\n",
            "Epoch 6 Batch 1900 Loss 5.5592 Accuracy 0.2090\n",
            "Epoch 6 Batch 2000 Loss 5.5618 Accuracy 0.2090\n",
            "Epoch 6 Batch 2100 Loss 5.5664 Accuracy 0.2090\n",
            "Epoch 6 Batch 2200 Loss 5.5685 Accuracy 0.2091\n",
            "Epoch 6 Batch 2300 Loss 5.5720 Accuracy 0.2091\n",
            "Epoch 6 Batch 2400 Loss 5.5735 Accuracy 0.2091\n",
            "Epoch 6 Batch 2500 Loss 5.5768 Accuracy 0.2092\n",
            "Epoch 6 Batch 2600 Loss 5.5788 Accuracy 0.2092\n",
            "Epoch 6 Batch 2700 Loss 5.5814 Accuracy 0.2092\n",
            "Epoch 6 Batch 2800 Loss 5.5848 Accuracy 0.2093\n",
            "Epoch 6 Batch 2900 Loss 5.5875 Accuracy 0.2093\n",
            "Epoch 6 Batch 3000 Loss 5.5894 Accuracy 0.2093\n",
            "Epoch 6 Batch 3100 Loss 5.5910 Accuracy 0.2093\n",
            "Epoch 6 Batch 3200 Loss 5.5923 Accuracy 0.2094\n",
            "Epoch 6 Batch 3300 Loss 5.5939 Accuracy 0.2094\n",
            "Epoch 6 Batch 3400 Loss 5.5960 Accuracy 0.2094\n",
            "Epoch 6 Batch 3500 Loss 5.5984 Accuracy 0.2095\n",
            "Epoch 6 Loss 5.5995 Accuracy 0.2095\n",
            "Time taken for 1 epoch: 1287.4987823963165 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 5.3161 Accuracy 0.2095\n",
            "Epoch 7 Batch 100 Loss 5.4321 Accuracy 0.2095\n",
            "Epoch 7 Batch 200 Loss 5.4360 Accuracy 0.2096\n",
            "Epoch 7 Batch 300 Loss 5.4471 Accuracy 0.2096\n",
            "Epoch 7 Batch 400 Loss 5.4683 Accuracy 0.2096\n",
            "Epoch 7 Batch 500 Loss 5.4813 Accuracy 0.2097\n",
            "Epoch 7 Batch 600 Loss 5.4830 Accuracy 0.2097\n",
            "Epoch 7 Batch 700 Loss 5.4928 Accuracy 0.2097\n",
            "Epoch 7 Batch 800 Loss 5.4947 Accuracy 0.2098\n",
            "Epoch 7 Batch 900 Loss 5.5018 Accuracy 0.2098\n",
            "Epoch 7 Batch 1000 Loss 5.5098 Accuracy 0.2098\n",
            "Epoch 7 Batch 1100 Loss 5.5157 Accuracy 0.2099\n",
            "Epoch 7 Batch 1200 Loss 5.5183 Accuracy 0.2099\n",
            "Epoch 7 Batch 1300 Loss 5.5213 Accuracy 0.2099\n",
            "Epoch 7 Batch 1400 Loss 5.5287 Accuracy 0.2100\n",
            "Epoch 7 Batch 1500 Loss 5.5315 Accuracy 0.2100\n",
            "Epoch 7 Batch 1600 Loss 5.5375 Accuracy 0.2100\n",
            "Epoch 7 Batch 1700 Loss 5.5414 Accuracy 0.2100\n",
            "Epoch 7 Batch 1800 Loss 5.5454 Accuracy 0.2101\n",
            "Epoch 7 Batch 1900 Loss 5.5478 Accuracy 0.2101\n",
            "Epoch 7 Batch 2000 Loss 5.5495 Accuracy 0.2101\n",
            "Epoch 7 Batch 2100 Loss 5.5526 Accuracy 0.2102\n",
            "Epoch 7 Batch 2200 Loss 5.5540 Accuracy 0.2102\n",
            "Epoch 7 Batch 2300 Loss 5.5572 Accuracy 0.2102\n",
            "Epoch 7 Batch 2400 Loss 5.5606 Accuracy 0.2103\n",
            "Epoch 7 Batch 2500 Loss 5.5619 Accuracy 0.2103\n",
            "Epoch 7 Batch 2600 Loss 5.5650 Accuracy 0.2103\n",
            "Epoch 7 Batch 2700 Loss 5.5673 Accuracy 0.2103\n",
            "Epoch 7 Batch 2800 Loss 5.5693 Accuracy 0.2104\n",
            "Epoch 7 Batch 2900 Loss 5.5731 Accuracy 0.2104\n",
            "Epoch 7 Batch 3000 Loss 5.5757 Accuracy 0.2104\n",
            "Epoch 7 Batch 3100 Loss 5.5782 Accuracy 0.2105\n",
            "Epoch 7 Batch 3200 Loss 5.5792 Accuracy 0.2105\n",
            "Epoch 7 Batch 3300 Loss 5.5818 Accuracy 0.2105\n",
            "Epoch 7 Batch 3400 Loss 5.5833 Accuracy 0.2105\n",
            "Epoch 7 Batch 3500 Loss 5.5858 Accuracy 0.2106\n",
            "Epoch 7 Loss 5.5874 Accuracy 0.2106\n",
            "Time taken for 1 epoch: 1286.8001022338867 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 5.2165 Accuracy 0.2106\n",
            "Epoch 8 Batch 100 Loss 5.4478 Accuracy 0.2106\n",
            "Epoch 8 Batch 200 Loss 5.4598 Accuracy 0.2107\n",
            "Epoch 8 Batch 300 Loss 5.4686 Accuracy 0.2107\n",
            "Epoch 8 Batch 400 Loss 5.4759 Accuracy 0.2107\n",
            "Epoch 8 Batch 500 Loss 5.4879 Accuracy 0.2108\n",
            "Epoch 8 Batch 600 Loss 5.4936 Accuracy 0.2108\n",
            "Epoch 8 Batch 700 Loss 5.4943 Accuracy 0.2108\n",
            "Epoch 8 Batch 800 Loss 5.4973 Accuracy 0.2109\n",
            "Epoch 8 Batch 900 Loss 5.5007 Accuracy 0.2109\n",
            "Epoch 8 Batch 1000 Loss 5.5042 Accuracy 0.2109\n",
            "Epoch 8 Batch 1100 Loss 5.5087 Accuracy 0.2109\n",
            "Epoch 8 Batch 1200 Loss 5.5098 Accuracy 0.2110\n",
            "Epoch 8 Batch 1300 Loss 5.5147 Accuracy 0.2110\n",
            "Epoch 8 Batch 1400 Loss 5.5192 Accuracy 0.2110\n",
            "Epoch 8 Batch 1500 Loss 5.5252 Accuracy 0.2111\n",
            "Epoch 8 Batch 1600 Loss 5.5286 Accuracy 0.2111\n",
            "Epoch 8 Batch 1700 Loss 5.5312 Accuracy 0.2111\n",
            "Epoch 8 Batch 1800 Loss 5.5358 Accuracy 0.2112\n",
            "Epoch 8 Batch 1900 Loss 5.5390 Accuracy 0.2112\n",
            "Epoch 8 Batch 2000 Loss 5.5416 Accuracy 0.2112\n",
            "Epoch 8 Batch 2100 Loss 5.5430 Accuracy 0.2113\n",
            "Epoch 8 Batch 2200 Loss 5.5467 Accuracy 0.2113\n",
            "Epoch 8 Batch 2300 Loss 5.5495 Accuracy 0.2113\n",
            "Epoch 8 Batch 2400 Loss 5.5526 Accuracy 0.2113\n",
            "Epoch 8 Batch 2500 Loss 5.5551 Accuracy 0.2114\n",
            "Epoch 8 Batch 2600 Loss 5.5562 Accuracy 0.2114\n",
            "Epoch 8 Batch 2700 Loss 5.5581 Accuracy 0.2114\n",
            "Epoch 8 Batch 2800 Loss 5.5588 Accuracy 0.2115\n",
            "Epoch 8 Batch 2900 Loss 5.5619 Accuracy 0.2115\n",
            "Epoch 8 Batch 3000 Loss 5.5650 Accuracy 0.2115\n",
            "Epoch 8 Batch 3100 Loss 5.5669 Accuracy 0.2115\n",
            "Epoch 8 Batch 3200 Loss 5.5691 Accuracy 0.2116\n",
            "Epoch 8 Batch 3300 Loss 5.5707 Accuracy 0.2116\n",
            "Epoch 8 Batch 3400 Loss 5.5726 Accuracy 0.2116\n",
            "Epoch 8 Batch 3500 Loss 5.5743 Accuracy 0.2117\n",
            "Epoch 8 Loss 5.5761 Accuracy 0.2117\n",
            "Time taken for 1 epoch: 1287.149216413498 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 5.5287 Accuracy 0.2117\n",
            "Epoch 9 Batch 100 Loss 5.4366 Accuracy 0.2117\n",
            "Epoch 9 Batch 200 Loss 5.4347 Accuracy 0.2117\n",
            "Epoch 9 Batch 300 Loss 5.4484 Accuracy 0.2118\n",
            "Epoch 9 Batch 400 Loss 5.4533 Accuracy 0.2118\n",
            "Epoch 9 Batch 500 Loss 5.4642 Accuracy 0.2118\n",
            "Epoch 9 Batch 600 Loss 5.4672 Accuracy 0.2119\n",
            "Epoch 9 Batch 700 Loss 5.4730 Accuracy 0.2119\n",
            "Epoch 9 Batch 800 Loss 5.4763 Accuracy 0.2119\n",
            "Epoch 9 Batch 900 Loss 5.4838 Accuracy 0.2120\n",
            "Epoch 9 Batch 1000 Loss 5.4896 Accuracy 0.2120\n",
            "Epoch 9 Batch 1100 Loss 5.4912 Accuracy 0.2120\n",
            "Epoch 9 Batch 1200 Loss 5.4948 Accuracy 0.2121\n",
            "Epoch 9 Batch 1300 Loss 5.4987 Accuracy 0.2121\n",
            "Epoch 9 Batch 1400 Loss 5.5000 Accuracy 0.2121\n",
            "Epoch 9 Batch 1500 Loss 5.5041 Accuracy 0.2122\n",
            "Epoch 9 Batch 1600 Loss 5.5082 Accuracy 0.2122\n",
            "Epoch 9 Batch 1700 Loss 5.5113 Accuracy 0.2122\n",
            "Epoch 9 Batch 1800 Loss 5.5150 Accuracy 0.2123\n",
            "Epoch 9 Batch 1900 Loss 5.5184 Accuracy 0.2123\n",
            "Epoch 9 Batch 2000 Loss 5.5232 Accuracy 0.2123\n",
            "Epoch 9 Batch 2100 Loss 5.5266 Accuracy 0.2123\n",
            "Epoch 9 Batch 2200 Loss 5.5280 Accuracy 0.2124\n",
            "Epoch 9 Batch 2300 Loss 5.5313 Accuracy 0.2124\n",
            "Epoch 9 Batch 2400 Loss 5.5349 Accuracy 0.2124\n",
            "Epoch 9 Batch 2500 Loss 5.5391 Accuracy 0.2125\n",
            "Epoch 9 Batch 2600 Loss 5.5417 Accuracy 0.2125\n",
            "Epoch 9 Batch 2700 Loss 5.5442 Accuracy 0.2125\n",
            "Epoch 9 Batch 2800 Loss 5.5468 Accuracy 0.2125\n",
            "Epoch 9 Batch 2900 Loss 5.5490 Accuracy 0.2126\n",
            "Epoch 9 Batch 3000 Loss 5.5520 Accuracy 0.2126\n",
            "Epoch 9 Batch 3100 Loss 5.5547 Accuracy 0.2126\n",
            "Epoch 9 Batch 3200 Loss 5.5588 Accuracy 0.2126\n",
            "Epoch 9 Batch 3300 Loss 5.5617 Accuracy 0.2127\n",
            "Epoch 9 Batch 3400 Loss 5.5643 Accuracy 0.2127\n",
            "Epoch 9 Batch 3500 Loss 5.5668 Accuracy 0.2127\n",
            "Epoch 9 Loss 5.5686 Accuracy 0.2127\n",
            "Time taken for 1 epoch: 1287.1786661148071 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 5.3614 Accuracy 0.2127\n",
            "Epoch 10 Batch 100 Loss 5.4162 Accuracy 0.2128\n",
            "Epoch 10 Batch 200 Loss 5.4336 Accuracy 0.2128\n",
            "Epoch 10 Batch 300 Loss 5.4422 Accuracy 0.2128\n",
            "Epoch 10 Batch 400 Loss 5.4559 Accuracy 0.2129\n",
            "Epoch 10 Batch 500 Loss 5.4552 Accuracy 0.2129\n",
            "Epoch 10 Batch 600 Loss 5.4593 Accuracy 0.2129\n",
            "Epoch 10 Batch 700 Loss 5.4704 Accuracy 0.2130\n",
            "Epoch 10 Batch 800 Loss 5.4741 Accuracy 0.2130\n",
            "Epoch 10 Batch 900 Loss 5.4804 Accuracy 0.2130\n",
            "Epoch 10 Batch 1000 Loss 5.4849 Accuracy 0.2131\n",
            "Epoch 10 Batch 1100 Loss 5.4867 Accuracy 0.2131\n",
            "Epoch 10 Batch 1200 Loss 5.4889 Accuracy 0.2131\n",
            "Epoch 10 Batch 1300 Loss 5.4920 Accuracy 0.2132\n",
            "Epoch 10 Batch 1400 Loss 5.4986 Accuracy 0.2132\n",
            "Epoch 10 Batch 1500 Loss 5.5027 Accuracy 0.2132\n",
            "Epoch 10 Batch 1600 Loss 5.5060 Accuracy 0.2132\n",
            "Epoch 10 Batch 1700 Loss 5.5106 Accuracy 0.2133\n",
            "Epoch 10 Batch 1800 Loss 5.5142 Accuracy 0.2133\n",
            "Epoch 10 Batch 1900 Loss 5.5155 Accuracy 0.2133\n",
            "Epoch 10 Batch 2000 Loss 5.5196 Accuracy 0.2134\n",
            "Epoch 10 Batch 2100 Loss 5.5209 Accuracy 0.2134\n",
            "Epoch 10 Batch 2200 Loss 5.5256 Accuracy 0.2134\n",
            "Epoch 10 Batch 2300 Loss 5.5288 Accuracy 0.2134\n",
            "Epoch 10 Batch 2400 Loss 5.5333 Accuracy 0.2135\n",
            "Epoch 10 Batch 2500 Loss 5.5361 Accuracy 0.2135\n",
            "Epoch 10 Batch 2600 Loss 5.5389 Accuracy 0.2135\n",
            "Epoch 10 Batch 2700 Loss 5.5399 Accuracy 0.2135\n",
            "Epoch 10 Batch 2800 Loss 5.5424 Accuracy 0.2136\n",
            "Epoch 10 Batch 2900 Loss 5.5444 Accuracy 0.2136\n",
            "Epoch 10 Batch 3000 Loss 5.5462 Accuracy 0.2136\n",
            "Epoch 10 Batch 3100 Loss 5.5486 Accuracy 0.2137\n",
            "Epoch 10 Batch 3200 Loss 5.5509 Accuracy 0.2137\n",
            "Epoch 10 Batch 3300 Loss 5.5530 Accuracy 0.2137\n",
            "Epoch 10 Batch 3400 Loss 5.5559 Accuracy 0.2137\n",
            "Epoch 10 Batch 3500 Loss 5.5572 Accuracy 0.2138\n",
            "Saving checkpoint for epoch 10 at /content/drive/MyDrive/DL Project/ckpt-8\n",
            "Epoch 10 Loss 5.5580 Accuracy 0.2138\n",
            "Time taken for 1 epoch: 1289.4316012859344 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "j5Qh_3Xx0S2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_article):\n",
        "    input_article = article_tokenizer.texts_to_sequences([input_article])\n",
        "    input_article = tf.keras.preprocessing.sequence.pad_sequences(input_article, maxlen=ENCODER_LEN, \n",
        "                                                                   padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_article[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index['<sos>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(DECODER_LEN):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index['<eos>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:51.132359Z",
          "iopub.execute_input": "2022-04-18T21:09:51.132701Z",
          "iopub.status.idle": "2022-04-18T21:09:51.144071Z",
          "shell.execute_reply.started": "2022-04-18T21:09:51.13267Z",
          "shell.execute_reply": "2022-04-18T21:09:51.143225Z"
        },
        "trusted": true,
        "id": "DMHcFFWy0S2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_article):\n",
        "    summarized = evaluate(input_article=input_article)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  \n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:51.931256Z",
          "iopub.execute_input": "2022-04-18T21:09:51.931941Z",
          "iopub.status.idle": "2022-04-18T21:09:51.940607Z",
          "shell.execute_reply.started": "2022-04-18T21:09:51.931899Z",
          "shell.execute_reply": "2022-04-18T21:09:51.93954Z"
        },
        "trusted": true,
        "id": "-K3LUP_10S2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions\n",
        "\n",
        "Below me make predictions on some texts to see how the model is performimg. Since this was a very basic approach the model wont perform that well but it can surely be improved."
      ],
      "metadata": {
        "id": "FUOx09ie0S2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article.iloc[5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:53.560362Z",
          "iopub.execute_input": "2022-04-18T21:09:53.560676Z",
          "iopub.status.idle": "2022-04-18T21:09:53.569911Z",
          "shell.execute_reply.started": "2022-04-18T21:09:53.560645Z",
          "shell.execute_reply": "2022-04-18T21:09:53.568875Z"
        },
        "trusted": true,
        "id": "OGgmpHOD0S2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[5][5:-5],\"\\n Predicted Summary : \", summarize(article.iloc[5]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:09:54.37659Z",
          "iopub.execute_input": "2022-04-18T21:09:54.376925Z",
          "iopub.status.idle": "2022-04-18T21:09:57.037805Z",
          "shell.execute_reply.started": "2022-04-18T21:09:54.376894Z",
          "shell.execute_reply": "2022-04-18T21:09:57.036889Z"
        },
        "trusted": true,
        "id": "sZj2LBuR0S2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3605ce97-5640-4465-90fc-3ecf4c77face"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   The Reverend Pat Storey, 53, is a married mother of two .\n",
            "She has made history by becoming the Bishop of Meath and Kildare .  \n",
            " Predicted Summary :  dr michael clarke is a former church of ireland she has a child with a child with a child and a child she says she is a great thing to do with her father\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article.iloc[16]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:12:02.74997Z",
          "iopub.execute_input": "2022-04-18T21:12:02.750305Z",
          "iopub.status.idle": "2022-04-18T21:12:02.757928Z",
          "shell.execute_reply.started": "2022-04-18T21:12:02.750272Z",
          "shell.execute_reply": "2022-04-18T21:12:02.75713Z"
        },
        "trusted": true,
        "id": "8BY-WQGD0S2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b98be9fa-b027-438a-e5da-a1e4fc60cf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<SOS> By . James Rush . Shocking video footage has emerged of the moment a man was paralysed from the waist down after he was kicked through the top window of a double-decker bus in London. CCTV footage of the incident was captured by a camera on a bus immediately behind the double-decker the man fell from near Finsbury Park, north London. The victim's sister has now said her brother was paralysed following the fall, in which he is understood to have broken his back. SCROLL DOWN FOR VIDEO . This is the shocking moment a man was kicked through the top window of a double-decker bus in London . The 43-year-old victim can be seen falling from the window and landing on the pavement below . The footage, taken on Seven Sisters Road on December 27, 2012, was shown on BBC Two's The Route Masters: Running London's Roads on Sunday. Footage meanwhile taken from inside the bus captured the moment the victim was kicked in the midriff before he fell out of the window. The man's sister, identified as Gillian, told the programme: 'At the moment they can't pinpoint a time on his recovery due to the fact that his back was so badly broken and his spinal chord was damaged. He needs to recover from his broken back before we even know if he's able to walk again. 'He's paralysed basically - he can't feel his legs, which is a life-changing experience. It's obviously going to be a bit hard for him.' Detective Constable Tony Barun, a specialist safer transport command officer for the Met, told the programme: 'It's still shocking. Although we see violence every day, it's our bread and butter, it's still shocking to see something as graphic and violent as this. 'We know these windows can be kicked out with a great deal of effort, but to see someone kicked so hard that he actually goes through the window and it pops the window out of its frame - I've never seen that before.' Police have said the man was left paralysed from the waist down following the incident in December 2012 . The footage, taken on Seven Sisters Road on December 27, 2012, was shown on BBC Two's The Route Masters: Running London's Roads on Sunday . A Metropolitan Police spokesman has told MailOnline the suspect jumped through the broken window before making off. The spokesman said: 'The victim was seriously injured and is now paralysed from the waist down.' On . January 16, 2013, a 38-year-old man was arrested and charged with GBH . with intent. He was later acquitted at Wood Green Crown Court on August . 19, 2013. The driver of the bus told the programme how he was alerted to the incident before he saw the man lying on the street. The man's sister, identified as Gillian, said her brother's back had been broken in the incident . He said: 'He was trying to get up but couldn't. He had spinal injuries. Then after a little while he started coughing up blood. Luckily there was a nurse passing by so she stayed with him.' According to official figures, more than 20,000 crimes were reported on London's buses in 2013. A special unit within the Metropolitan Police is funded by Transport for London in an attempt to cut rates. <EOS>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[16][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[16]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:11:43.233799Z",
          "iopub.execute_input": "2022-04-18T21:11:43.23412Z",
          "iopub.status.idle": "2022-04-18T21:11:47.13172Z",
          "shell.execute_reply.started": "2022-04-18T21:11:43.234085Z",
          "shell.execute_reply": "2022-04-18T21:11:47.13089Z"
        },
        "trusted": true,
        "id": "q9idxYN50S2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9f2bcd-1b75-42ec-c943-450713f97e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   CCTV footage shows moment man fell from top window of London bus .\n",
            "43-year-old man was kicked in midriff by unknown assailant on top deck .\n",
            "Force of impact caused window to pop out of frame and man tumbled out .\n",
            "Victim's sister says he has been  'paralysed' following fall in December 2012 .\n",
            "Footage emerges during BBC programme about London buses .  \n",
            "Predicted Summary :  the man was walking into the car in london on saturday he was arrested on suspicion of assault charges he was jailed for two years after he was arrested on suspicion of assault charges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[16][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[16]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY0oHrYbgKxk",
        "outputId": "b5a89efe-272d-4a1f-acf2-9ba35cfdaffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   CCTV footage shows moment man fell from top window of London bus .\n",
            "43-year-old man was kicked in midriff by unknown assailant on top deck .\n",
            "Force of impact caused window to pop out of frame and man tumbled out .\n",
            "Victim's sister says he has been  'paralysed' following fall in December 2012 .\n",
            "Footage emerges during BBC programme about London buses .  \n",
            "Predicted Summary :  man was caught on camera in london when he was hit by a train driver was caught on camera in london police were called to the scene and he was taken to hospital where he was taken to hospital\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[16][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[16]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWR69OGyVCmm",
        "outputId": "009659c2-9e5f-48bc-c8c5-9fc8b92fab14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   CCTV footage shows moment man fell from top window of London bus .\n",
            "43-year-old man was kicked in midriff by unknown assailant on top deck .\n",
            "Force of impact caused window to pop out of frame and man tumbled out .\n",
            "Victim's sister says he has been  'paralysed' following fall in December 2012 .\n",
            "Footage emerges during BBC programme about London buses .  \n",
            "Predicted Summary :  bus driver was attacked by a bus driver in london on saturday driver was attacked by a driver and his family were on the bus driver was on the road in london after he was attacked by a bus driver david taylor who was driving back to london\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article.iloc[23]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:12:08.675031Z",
          "iopub.execute_input": "2022-04-18T21:12:08.675387Z",
          "iopub.status.idle": "2022-04-18T21:12:08.681641Z",
          "shell.execute_reply.started": "2022-04-18T21:12:08.675357Z",
          "shell.execute_reply": "2022-04-18T21:12:08.680553Z"
        },
        "trusted": true,
        "id": "FJoaPNj-0S2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Real Headline : \", summary.iloc[23][5:-5],\"\\nPredicted Summary : \", summarize(article.iloc[23]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-18T21:12:15.989451Z",
          "iopub.execute_input": "2022-04-18T21:12:15.989852Z",
          "iopub.status.idle": "2022-04-18T21:12:23.012392Z",
          "shell.execute_reply.started": "2022-04-18T21:12:15.989814Z",
          "shell.execute_reply": "2022-04-18T21:12:23.011538Z"
        },
        "trusted": true,
        "id": "GfwuRw9T0S2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06220641-d410-45c1-8f22-5b3aec58546b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Headline :   Stephen Fidler, 41, was at beach with family in Qatar, Middle East .\n",
            "Inquest heard he decided to go for a dive after playing in the sea with sons .\n",
            "Climbed onto landing board platform before plunging head first into water .\n",
            "But water was shallower than he'd thought and he struck head on sea bed .  \n",
            "Predicted Summary :  david williams 24 died after being hit by water on the coast of the sea he had been on the coast of the sea with his wife and husband david williams mr williams died after being hit by a water and fell from the water\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yuNDCQYM0S2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}